{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import tensorqtl\n",
    "import os\n",
    "\n",
    "\n",
    "from tensorqtl import genotypeio, cis, trans, post, susie\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"torch: {torch.__version__} (CUDA {torch.version.cuda}), device: {device}\")\n",
    "print(f\"pandas {pd.__version__}\")\n",
    "\n",
    "os.chdir(\"/data/podo/Projects/project_HS/202404-sceQTLv7/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = sorted(os.listdir(\"01_calling_eQTL/01_00_pseudobulk_pipeline/tensorqtl_input/\"))\n",
    "list_pathes = [os.path.join(\"01_calling_eQTL/01_00_pseudobulk_pipeline/tensorqtl_input/\", i) for i in list_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8,len(list_pathes)):\n",
    "    path = list_pathes[i]\n",
    "    prefix = path.split(\"/\")[3][:-4]\n",
    "  \n",
    "    df_path = pd.read_csv(path, sep = \"\\t\").set_index('name')\n",
    "    \n",
    "    # parsing\n",
    "    geno_prefix = df_path.value['geno_prefix']\n",
    "    pheno_path =  df_path.value['pheno_path']\n",
    "    covs_path =  df_path.value['covs_path']\n",
    "    interaction_path = df_path.value['interaction_path']\n",
    "    \n",
    "    \n",
    "    # load phenotypes and covariates\n",
    "    phenotype_df, phenotype_pos_df = tensorqtl.read_phenotype_bed(pheno_path)\n",
    "    covariates_df = pd.read_csv(covs_path, sep='\\t', index_col=0).T\n",
    "    covariates_df = pd.merge(covariates_df.iloc[:,:15], covariates_df.iloc[:,15].str.get_dummies(sep=','), right_index=True, left_index=True).astype('float')\n",
    "    pr = genotypeio.PlinkReader(geno_prefix)\n",
    "    genotype_df = pr.load_genotypes()\n",
    "    variant_df = pr.bim.set_index('snp')[['chrom', 'pos']]\n",
    "    interaction_df = pd.read_csv(interaction_path, sep='\\t', index_col=0).T\n",
    "    print(all(phenotype_df.columns==covariates_df.index))\n",
    "    \n",
    "    # significant_stats\n",
    "    out_prefix = \"01_calling_eQTL/01_01_tensorqtl_out/\"+prefix\n",
    "    df_cis = cis.map_cis(genotype_df, variant_df,\n",
    "                phenotype_df.loc[phenotype_pos_df['chr'].isin(['chr'+str(i) for i in range(1,23)])],\n",
    "                phenotype_pos_df.loc[phenotype_pos_df['chr'].isin(['chr'+str(i) for i in range(1,23)])],\n",
    "                covariates_df=covariates_df, maf_threshold = 0.05)\n",
    "    #tensorqtl.calculate_qvalues(df_cis, fdr = 0.1)\n",
    "    df_cis.to_csv(out_prefix+\".map_cis.txt.gz\", sep = \"\\t\")\n",
    "    \n",
    "    out_prefix = \"01_calling_eQTL/01_02_tensorqtl_nominal/\"+prefix\n",
    "    print(all(phenotype_df.columns==covariates_df.index))\n",
    "    print(out_prefix)\n",
    "    \n",
    "    # nominal\n",
    "    cis.map_nominal(genotype_df, variant_df,\n",
    "        phenotype_df.loc[phenotype_pos_df['chr'].isin(['chr'+str(i) for i in range(1,23)])],\n",
    "        phenotype_pos_df.loc[phenotype_pos_df['chr'].isin(['chr'+str(i) for i in range(1,23)])],\n",
    "        covariates_df=covariates_df, prefix = out_prefix,\n",
    "        run_eigenmt=True, maf_threshold=0.05)\n",
    "    \n",
    "    out_prefix = \"01_calling_eQTL/01_03_tensorqtl_susie/\"+prefix\n",
    "    \n",
    "    # susie\n",
    "    df_cis = susie.map(genotype_df, variant_df,\n",
    "                phenotype_df.loc[phenotype_pos_df['chr'].isin(['chr'+str(i) for i in range(1,23)])],\n",
    "                phenotype_pos_df.loc[phenotype_pos_df['chr'].isin(['chr'+str(i) for i in range(1,23)])],\n",
    "                covariates_df=covariates_df, maf_threshold=0.05, max_iter=500)\n",
    "    df_cis.to_csv(out_prefix+\".susie_mapped.txt.gz\", sep = \"\\t\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
